//! Layout and bytecode synthesis.
//!
//! This module is responsible for taking the abstract blueprint generated by the blueprint
//! module and synthesizing it into concrete EVM bytecode instructions that are inserted
//! into the control flow graph. The layout process transforms the high-level obfuscation
//! plan into actual executable code that implements the multi-tier dispatcher pattern.
//!
//! Stub/decoy blocks
//!
//! Each tier we synthesize includes a trio of helper blocks:
//! * `invalid`: a `JUMPDEST` + `INVALID` sink used by decoys.
//! * `decoy`: looks like a controller but routes to `invalid` or on to the real controller
//!   after a conditional; its jump target is patched later (`decoy_patches`).
//! * `stub`: tiny trampoline that always jumps to the decoy; its PUSH immediate is patched later
//!   (`stub_patches`) to keep pointing at the decoy after PC reindexing.
//!
//! We track these PCs so downstream transforms can mark them as protected and avoid rewriting
//! their PUSH/JUMP patterns.

use super::blueprint::{ControllerPatternConfig, DispatcherBlueprint, TierAssignment};
use super::controller::{
    generate_byte_extraction_instructions, generate_storage_check_instructions,
};
use crate::function_dispatcher::token::generate_selector_token_mapping;
use crate::function_dispatcher::FunctionDispatcher;
use crate::Error;
use azoth_core::cfg_ir::{Block, BlockBody, BlockControl, CfgIrBundle};
use azoth_core::decoder::EncodedSize;
use azoth_core::decoder::Instruction;
use azoth_core::detection::{DispatcherInfo, FunctionSelector};
use azoth_core::Opcode;
use petgraph::graph::NodeIndex;
use std::collections::HashMap;
use tracing::debug;

struct TierNodes {
    stub_pc: usize,
    #[allow(dead_code)]
    decoy_pc: usize,
    invalid_pc: usize,
}

/// Stub patch information: (stub_node, stub_push_pc, push_width, decoy_node)
type StubPatchInfo = (NodeIndex, usize, u8, NodeIndex);

/// Decoy patch information: (decoy_node, push_pc, push_width, target_pc)
type DecoyPatchInfo = (NodeIndex, usize, u8, usize);

/// Controller patch information: (controller_node, push_pc, push_width, target_pc)
type ControllerPatchInfo = Vec<(NodeIndex, usize, u8, usize)>;

/// Result produced when a dispatch layout has been synthesised.
pub struct LayoutPlan {
    pub mapping: HashMap<u32, Vec<u8>>,
    pub dispatcher_modified: bool,
    /// Maps each selector to its controller entry PC for post-reindex patching
    pub controller_pcs: HashMap<u32, usize>,
    /// Dispatcher patch locations: (node, pc, push_width, selector)
    pub dispatcher_patches: Vec<(NodeIndex, usize, u8, u32)>,
    /// Stub patch locations: (stub_node, stub_push_pc, push_width, decoy_node)
    pub stub_patches: Vec<(NodeIndex, usize, u8, NodeIndex)>,
    /// Decoy patch locations: (decoy_node, push_pc, push_width, target_pc)
    pub decoy_patches: Vec<(NodeIndex, usize, u8, usize)>,
    /// Controller patch locations: (controller_node, push_pc, push_width, target_pc)
    pub controller_patches: Vec<(NodeIndex, usize, u8, usize)>,
}

pub fn apply_layout_plan(
    dispatcher: &FunctionDispatcher,
    ir: &mut CfgIrBundle,
    runtime: &[Instruction],
    index_by_pc: &HashMap<usize, (NodeIndex, usize)>,
    dispatcher_info: &DispatcherInfo,
    blueprint: &DispatcherBlueprint,
) -> crate::Result<Option<LayoutPlan>> {
    // `highest_pc` already returns the next free instruction PC (last instruction's pc + byte_size),
    // so we use it directly as the starting point for newly synthesized blocks.
    let mut next_pc = highest_pc(ir);
    debug!(
        "multi-tier: highest existing pc end=0x{:04x}, runtime_bounds={:?}",
        next_pc, ir.runtime_bounds
    );

    let mut tiers: HashMap<usize, Vec<&TierAssignment>> = HashMap::new();
    for assignment in &blueprint.selectors {
        tiers
            .entry(assignment.tier_index)
            .or_default()
            .push(assignment);
    }

    let mut tier_nodes: HashMap<usize, TierNodes> = HashMap::new();
    // Track stub → decoy jumps for post-reindex patching: (stub_node, stub_push_pc, push_width, decoy_node)
    let mut stub_patches = Vec::new();
    // Track decoy → target jumps for post-reindex patching: (decoy_node, push_pc, push_width, target_pc)
    let mut decoy_patches = Vec::new();
    // Track controller jump targets for post-reindex patching: (controller_node, push_pc, push_width, target_pc)
    let mut controller_patches = Vec::new();

    for (tier_index, assignments) in tiers.iter() {
        if *tier_index == 0 {
            continue;
        }

        let Some(primary) = assignments.first() else {
            continue;
        };

        let target_rel = primary.selector.target_address as usize;
        let target_pc = runtime_absolute(ir, target_rel);
        let (nodes, updated_pc, stub_patch_info, decoy_patch_info) =
            create_tier_nodes(ir, next_pc, target_pc)?;
        next_pc = updated_pc;
        tier_nodes.insert(*tier_index, nodes);
        if let Some((stub_node, stub_push_pc, push_width, decoy_node)) = stub_patch_info {
            stub_patches.push((stub_node, stub_push_pc, push_width, decoy_node));
        }
        if let Some((decoy_node, decoy_push_pc, push_width, target_pc)) = decoy_patch_info {
            decoy_patches.push((decoy_node, decoy_push_pc, push_width, target_pc));
        }
    }

    if let Some((start, end)) = ir.runtime_bounds {
        if next_pc > end {
            ir.runtime_bounds = Some((start, next_pc));
        }
    }

    // Build preserve_bytes map from blueprint controller patterns
    let mut preserve_bytes = HashMap::new();
    for assignment in &blueprint.selectors {
        if let Some(pattern) = blueprint.controller_patterns.get(&assignment.tier_index) {
            if pattern.use_byte_extraction {
                preserve_bytes.insert(assignment.selector.selector, pattern.byte_index);
            }
        }
    }

    // Generate 4-byte token mapping for selectors (preserving bytes as needed for extraction patterns)
    let seed = dispatcher
        .seed()
        .ok_or_else(|| Error::Generic("dispatcher: seed required for token mapping".into()))?;
    let mapping =
        generate_selector_token_mapping(&dispatcher_info.selectors, seed, &preserve_bytes)?;

    // Apply dispatcher patches: replace original selectors with derived tokens
    let mut dispatcher_modified =
        dispatcher.apply_dispatcher_patches(ir, runtime, index_by_pc, dispatcher_info, &mapping)?;

    let mut selector_entry_pcs = HashMap::new();
    for assignment in &blueprint.selectors {
        let target_rel = assignment.selector.target_address as usize;
        let target_abs = runtime_absolute(ir, target_rel);
        let tier_meta = tier_nodes.get(&assignment.tier_index);
        let stub_pc = tier_meta.map(|nodes| nodes.stub_pc).unwrap_or(target_abs);
        let invalid_pc = tier_meta
            .map(|nodes| nodes.invalid_pc)
            .unwrap_or(target_abs);

        let pattern_config = blueprint.controller_patterns.get(&assignment.tier_index);
        let (controller_pc, updated_pc, ctrl_patches) = create_selector_controller(
            ir,
            next_pc,
            stub_pc,
            invalid_pc,
            pattern_config,
            assignment.selector.selector,
        )?;
        next_pc = updated_pc;
        selector_entry_pcs.insert(assignment.selector.selector, controller_pc);
        // Collect controller patches for post-reindex patching
        controller_patches.extend(ctrl_patches);
    }

    // Update runtime bounds to include all newly created blocks
    if let Some((start, end)) = ir.runtime_bounds {
        if next_pc > end {
            ir.runtime_bounds = Some((start, next_pc));
        }
    }

    let mut edits = Vec::new();
    let mut dispatcher_patches = Vec::new();
    for assignment in &blueprint.selectors {
        let Some(&controller_pc) = selector_entry_pcs.get(&assignment.selector.selector) else {
            continue;
        };

        if let Some(instr_idx) = locate_target_push(runtime, &assignment.selector) {
            let instr = &runtime[instr_idx];
            let pc = instr.pc;
            let (node, _) = index_by_pc.get(&pc).ok_or_else(|| {
                Error::Generic(format!(
                    "multi-tier: dispatcher instruction at pc 0x{pc:04x} missing from CFG"
                ))
            })?;

            let push_width = match instr.op {
                Opcode::PUSH(width) => width,
                _ => continue,
            };
            let controller_rel = runtime_relative(ir, controller_pc);
            let formatted = format!(
                "{:0width$x}",
                controller_rel,
                width = push_width as usize * 2
            );
            edits.push((*node, pc, instr.op, Some(formatted)));

            // Store patch info for post-reindex update
            dispatcher_patches.push((*node, pc, push_width, assignment.selector.selector));
        } else {
            debug!(
                selector = format_args!("0x{:08x}", assignment.selector.selector),
                "multi-tier: unable to locate dispatcher target push"
            );
        }
    }

    if !edits.is_empty() && dispatcher.apply_instruction_replacements(ir, edits)? {
        dispatcher_modified = true;
    }

    Ok(Some(LayoutPlan {
        mapping,
        dispatcher_modified,
        controller_pcs: selector_entry_pcs,
        dispatcher_patches,
        stub_patches,
        decoy_patches,
        controller_patches,
    }))
}

fn highest_pc(ir: &CfgIrBundle) -> usize {
    ir.cfg
        .node_indices()
        .filter_map(|idx| match &ir.cfg[idx] {
            Block::Body(body) => body
                .instructions
                .last()
                .map(|instr| instr.pc + instr.byte_size()),
            _ => None,
        })
        .max()
        .unwrap_or(0)
}

fn minimal_push_width(value: usize) -> u8 {
    for width in 1..=32 {
        let max = if width == 32 {
            usize::MAX
        } else {
            (1usize << (width * 8)) - 1
        };
        if value <= max {
            return width as u8;
        }
    }
    32
}

fn format_immediate(value: u128, width: u8) -> String {
    format!("{:0width$x}", value, width = width as usize * 2)
}

fn runtime_relative(ir: &CfgIrBundle, pc: usize) -> usize {
    if let Some((start, _)) = ir.runtime_bounds {
        pc.saturating_sub(start)
    } else {
        pc
    }
}

fn runtime_absolute(ir: &CfgIrBundle, pc: usize) -> usize {
    if let Some((start, _)) = ir.runtime_bounds {
        start.saturating_add(pc)
    } else {
        pc
    }
}

fn create_tier_nodes(
    ir: &mut CfgIrBundle,
    mut next_pc: usize,
    target_pc: usize,
) -> crate::Result<(
    TierNodes,
    usize,
    Option<StubPatchInfo>,
    Option<DecoyPatchInfo>,
)> {
    let invalid_start = next_pc;
    let invalid_rel = runtime_relative(ir, invalid_start);
    let invalid_block = BlockBody {
        start_pc: invalid_start,
        instructions: vec![
            Instruction {
                pc: invalid_start,
                op: Opcode::JUMPDEST,
                imm: None,
            },
            Instruction {
                pc: invalid_start + 1,
                op: Opcode::INVALID,
                imm: Some("fe".to_string()), // Ensure it encodes as 0xfe, not a random byte
            },
        ],
        max_stack: 0,
        control: BlockControl::Terminal,
    };
    next_pc += 2;
    let invalid_node = ir.cfg.add_node(Block::Body(invalid_block));
    ir.pc_to_block.insert(invalid_start, invalid_node);
    ir.rebuild_edges_for_block(invalid_node)
        .map_err(|err| Error::CoreError(err.to_string()))?;

    let mut pc = next_pc;
    let decoy_start = pc;
    let invalid_width = minimal_push_width(invalid_rel);
    let target_rel = runtime_relative(ir, target_pc);
    let target_width = minimal_push_width(target_rel);
    let mut decoy_instructions = Vec::new();
    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::JUMPDEST,
        imm: None,
    });
    pc += 1;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::PUSH(1),
        imm: Some("01".to_string()),
    });
    pc += 2;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::PUSH(1),
        imm: Some("00".to_string()),
    });
    pc += 2;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::EQ,
        imm: None,
    });
    pc += 1;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::PUSH(invalid_width),
        imm: Some(format_immediate(invalid_rel as u128, invalid_width)),
    });
    pc += 1 + invalid_width as usize;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::JUMPI,
        imm: None,
    });
    pc += 1;

    // Track the decoy→target PUSH instruction for post-reindex patching
    let decoy_push_pc = pc;
    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::PUSH(target_width),
        imm: Some(format_immediate(target_rel as u128, target_width)),
    });
    pc += 1 + target_width as usize;

    decoy_instructions.push(Instruction {
        pc,
        op: Opcode::JUMP,
        imm: None,
    });
    pc += 1;

    let decoy_block = BlockBody {
        start_pc: decoy_start,
        instructions: decoy_instructions,
        max_stack: 2,
        control: BlockControl::Unknown,
    };
    let decoy_node = ir.cfg.add_node(Block::Body(decoy_block));
    ir.pc_to_block.insert(decoy_start, decoy_node);
    ir.rebuild_edges_for_block(decoy_node)
        .map_err(|err| Error::CoreError(err.to_string()))?;

    next_pc = pc;

    let stub_start = next_pc;
    let stub_target_rel = runtime_relative(ir, decoy_start);
    let stub_width = minimal_push_width(stub_target_rel);
    debug!(
        stub_start = format_args!("0x{:04x}", stub_start),
        decoy_start = format_args!("0x{:04x}", decoy_start),
        stub_target_rel = format_args!("0x{:x}", stub_target_rel),
        stub_width,
        "Creating stub block"
    );

    let stub_instructions = vec![
        Instruction {
            pc: stub_start,
            op: Opcode::JUMPDEST,
            imm: None,
        },
        Instruction {
            pc: stub_start + 1,
            op: Opcode::PUSH(stub_width),
            imm: Some(format_immediate(stub_target_rel as u128, stub_width)),
        },
        Instruction {
            pc: stub_start + 1 + 1 + stub_width as usize,
            op: Opcode::JUMP,
            imm: None,
        },
    ];
    let stub_block = BlockBody {
        start_pc: stub_start,
        instructions: stub_instructions,
        max_stack: 1,
        control: BlockControl::Unknown,
    };
    let stub_node = ir.cfg.add_node(Block::Body(stub_block));
    ir.pc_to_block.insert(stub_start, stub_node);
    ir.set_unconditional_jump(stub_node, decoy_node)
        .map_err(|err| Error::CoreError(err.to_string()))?;

    next_pc = stub_start + stub_width as usize + 3;

    // Track stub→decoy jump for post-reindex patching
    // Store the decoy_node so we can look up its start_pc after reindexing
    let stub_push_pc = stub_start + 1;
    let stub_patch_info = Some((stub_node, stub_push_pc, stub_width, decoy_node));

    // Track decoy→target jump for post-reindex patching
    // Store the target_pc so we can remap it after reindexing
    let decoy_patch_info = Some((decoy_node, decoy_push_pc, target_width, target_pc));

    Ok((
        TierNodes {
            stub_pc: stub_start,
            decoy_pc: decoy_start,
            invalid_pc: invalid_start,
        },
        next_pc,
        stub_patch_info,
        decoy_patch_info,
    ))
}

fn create_selector_controller(
    ir: &mut CfgIrBundle,
    mut next_pc: usize,
    stub_pc: usize,
    invalid_pc: usize,
    pattern_config: Option<&ControllerPatternConfig>,
    selector: u32,
) -> crate::Result<(usize, usize, ControllerPatchInfo)> {
    let start_pc = next_pc;
    let mut instructions = Vec::new();
    let mut patches = Vec::new(); // Track (push_pc, push_width, target_pc) for all jump targets
    let stub_rel = runtime_relative(ir, stub_pc);
    let invalid_rel = runtime_relative(ir, invalid_pc);

    debug!(
        selector = format_args!("0x{:08x}", selector),
        start_pc = format_args!("0x{:04x}", start_pc),
        stub_pc = format_args!("0x{:04x}", stub_pc),
        invalid_pc = format_args!("0x{:04x}", invalid_pc),
        has_pattern = pattern_config.is_some(),
        "Creating selector controller"
    );

    instructions.push(Instruction {
        pc: next_pc,
        op: Opcode::JUMPDEST,
        imm: None,
    });
    next_pc += 1;

    // Optionally add byte extraction pattern at the start of the controller
    if let Some(config) = pattern_config {
        if config.use_byte_extraction {
            // Extract the byte index from the selector for comparison
            let selector_bytes = selector.to_be_bytes();
            let expected_byte = selector_bytes[config.byte_index as usize];

            // Calculate where the JUMPDEST will be after the byte extraction block
            // The block consists of:
            // - PUSH1 0x00 + CALLDATALOAD + PUSH1 index + BYTE + PUSH1 expected + EQ (9 bytes fixed)
            // - PUSH(match_width) + imm + JUMPI (variable: 1 + match_width + 1)
            // - PUSH(fallback_width) + imm + JUMP (variable: 1 + fallback_width + 1)
            //
            // We need to calculate match_width, but it depends on byte_match_pc which we're calculating.
            // Use iterative approach: start with PUSH1, check if sufficient, adjust if needed.
            let byte_fail_rel = invalid_rel;
            let fallback_width = minimal_push_width(byte_fail_rel);
            let mut match_width = 1u8;
            let byte_match_pc;

            loop {
                let byte_block_size =
                    9 + (1 + match_width as usize + 1) + (1 + fallback_width as usize + 1);
                let candidate_pc = next_pc + byte_block_size;
                let candidate_rel = runtime_relative(ir, candidate_pc);
                let required_width = minimal_push_width(candidate_rel);

                if required_width <= match_width {
                    byte_match_pc = candidate_pc;
                    break;
                }
                match_width = required_width;
            }

            let byte_instrs = generate_byte_extraction_instructions(
                next_pc,
                config.byte_index,
                expected_byte,
                runtime_relative(ir, byte_match_pc),
                byte_fail_rel,
            );
            let byte_block_size = byte_instrs.size();

            // Track PUSH instructions for jump targets in byte extraction pattern
            // Pattern: ..., PUSH <match_target>, JUMPI, PUSH <fallback_target>, JUMP
            for i in 0..byte_instrs.len().saturating_sub(1) {
                if let Opcode::PUSH(width) = byte_instrs[i].op {
                    let next_op = &byte_instrs[i + 1].op;
                    if matches!(next_op, Opcode::JUMPI | Opcode::JUMP) {
                        // This PUSH is a jump target that needs patching
                        let push_pc = byte_instrs[i].pc;
                        let target_pc = if matches!(next_op, Opcode::JUMPI) {
                            byte_match_pc // JUMPI target (match path)
                        } else {
                            invalid_pc // JUMP target (fallback to invalid)
                        };
                        patches.push((push_pc, width, target_pc));
                    }
                }
            }

            // Add byte extraction instructions
            for instr in byte_instrs {
                instructions.push(instr);
            }
            next_pc += byte_block_size;

            // Add a JUMPDEST after byte extraction for the match path
            // This should now be at the correct address that the instructions expect
            instructions.push(Instruction {
                pc: next_pc,
                op: Opcode::JUMPDEST,
                imm: None,
            });
            next_pc += 1;

            // Verify our calculation was correct
            debug_assert_eq!(
                next_pc - 1,
                byte_match_pc,
                "byte extraction JUMPDEST mismatch"
            );
        }

        // Optionally add storage check pattern
        if config.use_storage_checks {
            let storage_instrs = generate_storage_check_instructions(
                next_pc,
                config.storage_slot,
                stub_rel,    // If storage is zero (default), go to stub (real path)
                invalid_rel, // If storage is non-zero, trap at invalid
            );
            let storage_block_size = storage_instrs.size();

            // Track PUSH instructions for jump targets in storage check pattern
            // Pattern: ..., PUSH <match_target>, JUMPI, PUSH <fallback_target>, JUMP
            for i in 0..storage_instrs.len().saturating_sub(1) {
                if let Opcode::PUSH(width) = storage_instrs[i].op {
                    let next_op = &storage_instrs[i + 1].op;
                    if matches!(next_op, Opcode::JUMPI | Opcode::JUMP) {
                        // This PUSH is a jump target that needs patching
                        let push_pc = storage_instrs[i].pc;
                        let target_pc = if matches!(next_op, Opcode::JUMPI) {
                            stub_pc // JUMPI target (match path - jump to stub)
                        } else {
                            invalid_pc // JUMP target (fallback to invalid)
                        };
                        patches.push((push_pc, width, target_pc));
                    }
                }
            }

            for instr in storage_instrs {
                instructions.push(instr);
            }
            next_pc += storage_block_size;
        }
    }

    let stub_width = minimal_push_width(stub_rel);
    let final_push_pc = next_pc;
    instructions.push(Instruction {
        pc: next_pc,
        op: Opcode::PUSH(stub_width),
        imm: Some(format_immediate(stub_rel as u128, stub_width)),
    });
    next_pc += 1 + stub_width as usize;

    instructions.push(Instruction {
        pc: next_pc,
        op: Opcode::JUMP,
        imm: None,
    });
    next_pc += 1;

    // Track the final PUSH for stub jump
    patches.push((final_push_pc, stub_width, stub_pc));

    let block = BlockBody {
        start_pc,
        instructions: instructions.clone(),
        max_stack: 2,
        control: BlockControl::Unknown,
    };

    debug!(
        selector = format_args!("0x{:08x}", selector),
        start_pc = format_args!("0x{:04x}", start_pc),
        end_pc = format_args!("0x{:04x}", next_pc),
        instruction_count = instructions.len(),
        opcodes = format_args!(
            "{:?}",
            instructions
                .iter()
                .map(|i| format!("{:?}", i.op))
                .collect::<Vec<_>>()
        ),
        "Controller created"
    );

    let node = ir.cfg.add_node(Block::Body(block));
    ir.pc_to_block.insert(start_pc, node);
    ir.rebuild_edges_for_block(node)
        .map_err(|err| Error::CoreError(err.to_string()))?;

    // Convert patches to include node index: (node, push_pc, push_width, target_pc)
    let controller_patches: ControllerPatchInfo = patches
        .into_iter()
        .map(|(push_pc, push_width, target_pc)| (node, push_pc, push_width, target_pc))
        .collect();

    Ok((start_pc, next_pc, controller_patches))
}

fn locate_target_push(runtime: &[Instruction], selector: &FunctionSelector) -> Option<usize> {
    let target = selector.target_address as usize;
    for (idx, instr) in runtime
        .iter()
        .enumerate()
        .skip(selector.instruction_index + 1)
    {
        match instr.op {
            Opcode::JUMPI => break,
            Opcode::PUSH(_) | Opcode::PUSH0 => {
                if instr
                    .imm
                    .as_ref()
                    .and_then(|imm| usize::from_str_radix(imm, 16).ok())
                    == Some(target)
                {
                    return Some(idx);
                }
            }
            _ => {}
        }
    }
    None
}
